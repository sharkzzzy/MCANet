长版本：好的，我完整重写第二章，确保每个概念都有"为什么需要→核心思想→具体实现→与本文工作的联系"的完整逻辑链，公式不堆砌，每个公式都有充分的物理含义解释。

---

# 第二章 相关理论与技术基础

## 2.1 引言

本文的研究工作主要基于状态空间模型和注意力机制等深度学习方法，在单模态和多模态遥感图像语义分割领域展开。为建立后续研究的理论基础，本章将系统介绍相关的核心理论与关键技术。首先，阐述语义分割任务的基本概念和编码器-解码器架构的设计原理；其次，详细介绍状态空间模型的数学基础及其从S4到Mamba的技术演进；然后，介绍本文涉及的通道注意力、空间注意力和交叉注意力等机制的原理与实现；接着，分析光学遥感图像与SAR图像的数据特性及其互补关系；随后，介绍本文实验所采用的四个公开数据集及语义分割任务的评价指标；最后，对本章内容进行小结。

## 2.2 语义分割基础

### 2.2.1 语义分割任务概述

语义分割是计算机视觉领域中像素级理解任务的核心代表，其目标是对输入图像中的每一个像素赋予一个语义类别标签。与图像分类任务仅需输出整幅图像的单一类别标签不同，语义分割要求模型在理解"图像中有什么"的同时，精确地确定"每个目标在哪里"，即同时完成语义理解和空间定位两个目标。

形式化地，给定一幅输入图像 $I \in \mathbb{R}^{H \times W \times C}$，其中 $H$、$W$、$C$ 分别表示图像的高度、宽度和通道数，语义分割的目标是学习一个映射函数 $f$，将输入图像映射为一幅与原图尺寸相同的标签图 $Y \in \{0, 1, \ldots, K-1\}^{H \times W}$，其中 $K$ 为预定义的类别总数。标签图中每个位置 $(i, j)$ 的值 $y_{ij}$ 即为该像素所属的语义类别。

在遥感图像语义分割中，常见的语义类别包括建筑物、道路、植被、水体、裸地、车辆等地物类型。与自然场景图像相比，遥感图像的语义分割具有以下特殊性：第一，遥感图像分辨率高、覆盖面积大，单幅图像可能包含数千万甚至上亿个像素，对算法的计算效率提出了极高要求；第二，遥感图像中地物尺度差异显著，同一场景中既有数百米范围的大面积农田，也有仅数米大小的单辆车辆，要求模型具备强大的多尺度建模能力；第三，遥感图像采用俯视角度拍摄，地物呈现的形态与日常视角存在较大差异，且不同类别之间的边界往往模糊不清，增加了精确分割的难度。这些特殊性构成了遥感图像语义分割研究的核心挑战，也是本文方法设计的重要出发点。

### 2.2.2 编码器-解码器架构

编码器-解码器架构是当前语义分割领域最主流的网络设计范式。该架构的设计动机源于语义分割任务的内在矛盾：一方面，为了准确判断每个像素的语义类别，模型需要通过逐层抽象提取高层语义特征，而这一过程不可避免地会降低特征图的空间分辨率；另一方面，分割任务要求输出与原图尺寸相同的逐像素预测，需要精确的空间位置信息。编码器-解码器架构通过将这两个相互矛盾的需求分别交由编码器和解码器两个阶段处理，巧妙地实现了语义理解与空间定位的协同。

**编码器**承担特征提取的任务，其核心功能是从输入图像中逐层提取从低级到高级的层次化特征表示。以本文采用的ResNet-18为例，编码器由四个残差阶段（Stage）组成，每个阶段通过卷积操作和下采样操作将特征图的空间分辨率降低一半，同时将通道数增加一倍。具体而言，假设输入图像的尺寸为 $H \times W \times 3$，四个阶段分别输出尺寸为 $\frac{H}{4} \times \frac{W}{4} \times 64$、$\frac{H}{8} \times \frac{W}{8} \times 128$、$\frac{H}{16} \times \frac{W}{16} \times 256$ 和 $\frac{H}{32} \times \frac{W}{32} \times 512$ 的特征图。随着层级的加深，特征图的空间分辨率逐步降低，但其中包含的语义信息逐步增强：浅层特征图保留了丰富的边缘、纹理等局部空间细节，但语义信息较为薄弱；深层特征图具有较强的语义抽象能力，能够区分不同类别的地物，但空间细节已经大量丢失。

编码器中的下采样操作（如步幅为2的卷积或池化）在提升语义抽象能力的同时，不可逆地丢弃了空间位置信息。以一个 $2 \times 2$ 的最大池化操作为例，它将每 $2 \times 2$ 个相邻像素合并为一个像素，特征图面积缩小为原来的四分之一。这意味着原始图像中四个相邻像素的精确位置区别被消除，仅保留了最显著的特征响应。经过四次下采样后，最终特征图的每个像素对应原图 $32 \times 32$ 个像素的区域，空间精度已远远不足以支撑像素级的精确分割。

[此处插入图：编码器特征层次化示意图。展示ResNet-18四个阶段的特征图，从左到右尺寸逐渐减小、通道数逐渐增加。浅层标注"边缘/纹理信息丰富，语义信息弱"，深层标注"语义信息强，空间细节丢失"。]

**解码器**的功能是将编码器输出的低分辨率高语义特征逐步恢复至原始分辨率，生成像素级的分割预测图。解码器的工作过程与编码器相反：通过逐层上采样操作（如双线性插值或转置卷积）逐步提高特征图的空间分辨率，同时通过卷积操作对上采样后的特征进行精细化处理。然而，仅靠上采样操作无法真正"恢复"编码器中已丢失的空间细节。上采样本质上是一种插值操作，只能使特征图在空间维度上变得更大，但无法凭空创造出编码过程中被丢弃的精确位置和边缘信息。这就引出了编码器-解码器架构中最关键的设计要素——跳跃连接。

**跳跃连接（Skip Connection）** 在编码器的各层与解码器的对应层之间建立直接的信息传递通道。其核心思想是：编码器浅层的特征图虽然语义信息较弱，但保留了精确的空间位置和边缘细节；解码器在恢复空间分辨率时，可以直接利用这些来自编码器的高分辨率空间信息，弥补上采样过程中无法恢复的细节。具体实现方式通常是将编码器某层的特征图与解码器对应层上采样后的特征图进行拼接（concatenation）或逐元素相加（element-wise addition），然后通过卷积操作融合两者的信息。

[此处插入图：完整的编码器-解码器架构示意图（U形结构）。左侧编码器逐层下采样（标注各层尺寸和通道数），右侧解码器逐层上采样，中间用水平箭头标注跳跃连接。标注编码器各层特征的特点（浅层→空间细节，深层→语义信息）以及解码器如何通过跳跃连接融合两者。]

通过编码器-解码器架构和跳跃连接的协同工作，模型能够同时获取深层的语义理解能力和浅层的空间定位精度，有效缓解了语义抽象与空间精度之间的矛盾。这一架构范式被广泛应用于各种语义分割网络中，本文提出的DP-UNet同样采用编码器-解码器架构作为整体框架，以ResNet-18作为编码器骨干提取多层级特征，以DVSS模块构建解码器实现特征的渐进式恢复，并通过MSK模块增强跳跃连接中的多尺度特征融合。

### 2.2.3 损失函数

损失函数用于量化模型预测结果与真实标签之间的差异，是驱动模型参数优化的核心要素。损失函数的设计直接影响模型的训练方向和最终性能。在语义分割任务中，由于不同类别的像素数量往往严重不平衡（例如遥感图像中背景类像素可能占总像素的50%以上，而车辆类像素可能不足1%），单一的损失函数往往难以全面指导模型优化。因此，本文采用交叉熵损失与Dice损失的联合损失来训练模型，综合利用两者各自的优势。

**交叉熵损失（Cross-Entropy Loss）** 是语义分割中最基础也最广泛使用的损失函数，其核心思想是衡量模型预测的概率分布与真实标签分布之间的差异。在语义分割任务中，模型对每个像素输出一个 $K$ 维的概率向量（通过Softmax函数将网络输出转化为各类别的概率），真实标签则可以表示为独热编码的 $K$ 维向量（仅在真实类别位置为1，其余位置为0）。交叉熵损失的计算公式为：

$$\mathcal{L}_{CE} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{k=0}^{K-1} y_{i,k} \log(\hat{y}_{i,k})$$

其中，$N$ 为图像中的像素总数，$K$ 为类别总数，$y_{i,k}$ 为第 $i$ 个像素的真实标签的独热编码，$\hat{y}_{i,k}$ 为模型预测第 $i$ 个像素属于类别 $k$ 的概率。由于真实标签是独热编码，上式可以简化为：

$$\mathcal{L}_{CE} = -\frac{1}{N}\sum_{i=1}^{N} \log(\hat{y}_{i, c_i})$$

其中，$c_i$ 为第 $i$ 个像素的真实类别。这意味着交叉熵损失本质上是在惩罚模型对真实类别预测概率的不足：当模型对真实类别给出接近1的概率时，$-\log(\hat{y}_{i, c_i})$ 趋近于0，损失很小；当模型对真实类别给出接近0的概率时，损失值急剧增大。

交叉熵损失对每个像素独立计算，能够提供稳定的逐像素梯度信号，有利于模型在训练初期快速收敛。然而，它的一个显著局限是对类别不平衡问题敏感。由于损失值是所有像素损失的平均，当某一类别的像素数量远多于其他类别时，该类别对总损失的贡献占据主导地位，导致模型倾向于将更多像素预测为多数类以降低整体损失，从而忽视了少数类的分割质量。

**Dice损失（Dice Loss）** 从区域重叠的角度评估分割质量，能够有效缓解类别不平衡问题。Dice损失基于Dice系数设计，Dice系数最初用于衡量两个集合之间的相似度，在语义分割中用于度量预测区域与真实区域的重叠程度。对于某一类别，Dice系数可以直观理解为"预测正确的区域面积占预测区域与真实区域总面积的比例"。Dice损失定义为：

$$\mathcal{L}_{Dice} = 1 - \frac{2\sum_{i=1}^{N} y_i \hat{y}_i + \epsilon}{\sum_{i=1}^{N} y_i + \sum_{i=1}^{N} \hat{y}_i + \epsilon}$$

其中，$y_i$ 为第 $i$ 个像素的真实标签（0或1），$\hat{y}_i$ 为模型对该像素的预测概率，$\epsilon$ 为平滑因子（通常取 $10^{-5}$），用于避免分母为零的数值问题。分子中的 $\sum y_i \hat{y}_i$ 表示预测区域与真实区域的"交集"（以概率形式近似），分母中的 $\sum y_i + \sum \hat{y}_i$ 表示两个区域的面积之和。

Dice损失之所以对类别不平衡具有较好的鲁棒性，关键在于其计算方式：它关注的是预测区域与真实区域的相对重叠比例，而非绝对的像素数量。对于一个仅占图像1%面积的少数类别，即使其像素数量很少，只要模型对该区域的预测不准确，Dice系数的分子（交集）就会明显偏小，导致损失值增大。这使得少数类别在损失函数中获得了与其面积占比不成正比的、更高的优化权重。

然而，Dice损失也有其不足之处。由于它是基于整个区域计算的全局指标，每个像素的梯度信号不仅取决于自身的预测值，还受到同类别所有其他像素预测值的影响，这导致梯度信号的稳定性不如交叉熵损失，在训练初期可能出现较大的波动。

基于以上分析，本文采用交叉熵损失与Dice损失的联合损失来训练模型：

$$\mathcal{L} = \mathcal{L}_{CE} + \mathcal{L}_{Dice}$$

两者的结合取长补短：交叉熵损失提供稳定的逐像素梯度信号，确保训练过程的平稳收敛；Dice损失从区域重叠的角度进行优化，增强模型对少数类别的关注，提升整体分割质量。

## 2.3 状态空间模型

状态空间模型是本文网络架构的核心理论基础，DP-UNet解码器中的DVSS模块即以状态空间模型作为全局上下文建模的核心引擎。本节将从连续状态空间模型的基本定义出发，阐述其在深度学习中的离散化实现方式，进而分析从S4到Mamba的关键技术突破，最后介绍将一维SSM扩展到二维图像处理的SS2D机制。

### 2.3.1 连续状态空间模型

状态空间模型起源于控制理论和信号处理领域，是一类通过隐状态的线性动力学方程来描述系统输入输出关系的数学模型。其基本思想是：系统在任意时刻的行为可以通过一组"隐状态"来完整描述，这些隐状态在外部输入的驱动下随时间演化，而系统的输出则由当前隐状态决定。

连续时间的状态空间模型由以下两个方程定义：

$$h'(t) = \mathbf{A}h(t) + \mathbf{B}x(t)$$

$$y(t) = \mathbf{C}h(t) + \mathbf{D}x(t)$$

第一个方程称为**状态方程**，描述了隐状态 $h(t) \in \mathbb{R}^{N}$ 如何在时间维度上演化。方程右侧包含两项：$\mathbf{A}h(t)$ 表示隐状态的自演化，即系统在没有外部输入时隐状态自身的动态变化规律，状态转移矩阵 $\mathbf{A} \in \mathbb{R}^{N \times N}$ 决定了这种自演化的方向和速率；$\mathbf{B}x(t)$ 表示外部输入 $x(t)$ 对隐状态的影响，输入矩阵 $\mathbf{B} \in \mathbb{R}^{N \times 1}$ 决定了输入信号以何种方式被写入隐状态。直观理解，隐状态就像一个"记忆容器"，它持续地从输入中吸收新信息（通过 $\mathbf{B}$），同时按照固定的规律更新和遗忘旧信息（通过 $\mathbf{A}$）。

第二个方程称为**观测方程**，描述了如何从隐状态中提取输出信息。输出矩阵 $\mathbf{C} \in \mathbb{R}^{1 \times N}$ 决定了从 $N$ 维隐状态中选取哪些维度的信息用于生成输出 $y(t)$。直连矩阵 $\mathbf{D} \in \mathbb{R}$ 提供了输入到输出的直接通路，在实际应用中通常设置为零，因为这种直连效果可以通过网络中的残差连接来实现。

状态空间模型与循环神经网络（RNN）在形式上具有相似性——两者都通过隐状态的递推来积累序列信息。然而，SSM的关键优势在于其线性动力学特性：状态方程中不包含非线性激活函数，隐状态的演化完全由线性运算驱动。这一特性使得SSM可以被转化为全局卷积的形式进行高效并行计算（详见2.3.2节），克服了RNN只能逐步递推、无法并行训练的根本缺陷。

### 2.3.2 离散化与计算实现

深度学习中的数据通常以离散序列的形式存在（如经过分块处理的图像特征序列），因此需要将上述连续时间的SSM离散化为离散时间系统。离散化过程的核心是引入一个步长参数 $\Delta > 0$，它控制连续模型在时间轴上的采样间隔——较大的 $\Delta$ 意味着采样更稀疏，系统对输入的响应更慢但覆盖的时间范围更广；较小的 $\Delta$ 意味着采样更密集，系统对输入的响应更灵敏但关注的时间范围较窄。

采用零阶保持（Zero-Order Hold, ZOH）方法进行离散化。ZOH方法假设在每个采样间隔 $\Delta$ 内，输入信号保持恒定。在此假设下，连续系统的精确离散化结果为：

$$\overline{\mathbf{A}} = \exp(\Delta \mathbf{A})$$

$$\overline{\mathbf{B}} = (\Delta \mathbf{A})^{-1}(\exp(\Delta \mathbf{A}) - \mathbf{I}) \cdot \Delta \mathbf{B}$$

其中，$\overline{\mathbf{A}}$ 和 $\overline{\mathbf{B}}$ 分别为离散化后的状态转移矩阵和输入矩阵，$\exp(\cdot)$ 为矩阵指数运算，$\mathbf{I}$ 为单位矩阵。离散化后的系统方程变为：

$$h_t = \overline{\mathbf{A}} h_{t-1} + \overline{\mathbf{B}} x_t$$

$$y_t = \mathbf{C} h_t$$

上述递推公式的物理含义非常直观：在第 $t$ 个时间步，新的隐状态 $h_t$ 由两部分组成——前一时刻隐状态 $h_{t-1}$ 经过矩阵 $\overline{\mathbf{A}}$ 变换后保留的历史信息，加上当前输入 $x_t$ 经过矩阵 $\overline{\mathbf{B}}$ 编码后注入的新信息。矩阵 $\overline{\mathbf{A}}$ 可以理解为"记忆衰减系数"，它决定了历史信息在传递过程中被保留多少、遗忘多少；矩阵 $\overline{\mathbf{B}}$ 可以理解为"输入门控"，它决定了新输入以何种方式、多大强度被写入记忆。

离散SSM的一个重要特性是它同时具备**递推**和**卷积**两种等价的计算模式：

**递推模式**：按照上述递推公式逐步计算 $h_1, h_2, \ldots, h_L$，每一步的计算仅依赖前一步的结果和当前输入。这种模式的计算复杂度为 $O(L)$（$L$ 为序列长度），且每一步仅需常数级的存储空间，非常适合推理阶段的自回归生成。但其缺点是无法并行——第 $t$ 步的计算必须等待第 $t-1$ 步完成后才能进行。

**卷积模式**：将递推公式展开后，可以发现输出序列 $y$ 可以表示为输入序列 $x$ 与一个固定卷积核 $\overline{\mathbf{K}}$ 的卷积：

$$\overline{\mathbf{K}} = (\mathbf{C}\overline{\mathbf{B}}, \mathbf{C}\overline{\mathbf{A}}\overline{\mathbf{B}}, \mathbf{C}\overline{\mathbf{A}}^2\overline{\mathbf{B}}, \ldots, \mathbf{C}\overline{\mathbf{A}}^{L-1}\overline{\mathbf{B}})$$

$$y = x * \overline{\mathbf{K}}$$

该卷积核的第 $t$ 个元素 $\mathbf{C}\overline{\mathbf{A}}^t\overline{\mathbf{B}}$ 表示的是：距离当前位置 $t$ 步之前的输入对当前输出的影响强度。随着 $t$ 的增大，如果 $\overline{\mathbf{A}}$ 的特征值模小于1，则影响逐渐衰减，体现了"近期信息影响大、远期信息影响小"的记忆特性。这种卷积形式可以利用快速傅里叶变换（FFT）在 $O(L \log L)$ 的时间内完成计算，且所有位置的输出可以并行得到，非常适合训练阶段的高效并行计算。

SSM同时支持递推和卷积两种计算模式，使其在训练效率和推理效率上均具有优势，这是其相比Transformer和RNN的一个重要特点。

### 2.3.3 从S4到Mamba的演进

理解了SSM的基本原理后，接下来分析其在深度学习序列建模中的关键技术演进。这一演进过程围绕一个核心问题展开：**如何让SSM在保持线性计算效率的同时，具备对输入内容的选择性处理能力**。

**S4（Structured State Space for Sequence Modeling）** 是2022年Gu等人提出的结构化状态空间模型，是将SSM成功应用于深度学习序列建模的里程碑工作。S4面临的首要挑战是：在实际训练中，状态转移矩阵 $\mathbf{A}$ 的矩阵指数运算 $\exp(\Delta \mathbf{A})$ 在 $\mathbf{A}$ 为一般矩阵时计算成本极高，且容易出现数值不稳定的问题（特征值过大导致梯度爆炸，特征值过小导致梯度消失）。

S4通过两项关键技术解决了这些问题。第一，S4对状态转移矩阵 $\mathbf{A}$ 采用了HiPPO（High-order Polynomial Projection Operators）初始化策略。HiPPO理论指出，特定结构的 $\mathbf{A}$ 矩阵能够使隐状态最优地压缩和记忆连续信号的历史信息——具体而言，隐状态的每个维度对应一个正交多项式的系数，整个隐状态向量就构成了对历史输入信号的最优多项式逼近。这种初始化使得SSM从一开始就具备了良好的长距离记忆能力。第二，S4将 $\mathbf{A}$ 矩阵参数化为对角加低秩（DPLR）的特殊结构，利用这种结构的数学性质将矩阵指数运算和卷积核计算转化为高效的频域操作，使得S4可以在 $O(L \log L)$ 的时间复杂度内处理长度为 $L$ 的序列。

S4在Long Range Arena等长序列建模基准测试中首次取得了突破性成果，证明了SSM在捕获长距离依赖关系方面的巨大潜力。然而，S4存在一个根本性的局限：其参数 $\mathbf{A}$、$\mathbf{B}$、$\mathbf{C}$ 和 $\Delta$ 在训练完成后即固定不变，对所有输入使用完全相同的状态转移规则。这种**线性时不变**（Linear Time-Invariant, LTI）特性意味着模型无法根据输入内容自适应地调整信息处理策略。例如，当处理一段包含重要地物特征和无关背景的像素序列时，S4对两者使用完全相同的"记忆-遗忘"规则，无法做到"选择性地保留重要信息、过滤无关噪声"。

**Mamba** 是2023年Gu和Dao提出的选择性状态空间模型，其核心创新在于将S4的固定参数升级为**输入依赖的动态参数**，从根本上赋予了SSM对输入内容的选择性处理能力。具体而言，Mamba将 $\mathbf{B}$、$\mathbf{C}$ 矩阵和步长参数 $\Delta$ 参数化为输入 $x$ 的函数：

$$\mathbf{B}_t = s_B(x_t), \quad \mathbf{C}_t = s_C(x_t), \quad \Delta_t = \text{softplus}(s_\Delta(x_t))$$

其中，$s_B$、$s_C$ 和 $s_\Delta$ 为可学习的线性投影。这种输入依赖的参数化赋予了模型内容感知的选择性：

- **步长 $\Delta_t$ 的选择性**：$\Delta_t$ 控制着离散化的精度和隐状态的更新幅度。当模型遇到重要的输入时，可以学习产生较大的 $\Delta_t$，使得 $\overline{\mathbf{B}}_t$ 增大、$\overline{\mathbf{A}}_t$ 趋向于遗忘旧信息，从而让当前输入被强力写入隐状态并覆盖先前的记忆；当遇到不相关的输入时，模型产生较小的 $\Delta_t$，使得隐状态几乎不受当前输入的影响而保持先前的记忆。这种机制类似于LSTM中的"输入门"和"遗忘门"，但以更简洁高效的方式实现。
- **输入矩阵 $\mathbf{B}_t$ 的选择性**：$\mathbf{B}_t$ 决定了当前输入如何被编码到隐状态中。输入依赖的 $\mathbf{B}_t$ 使模型能够根据输入内容选择性地提取不同维度的信息写入隐状态。
- **输出矩阵 $\mathbf{C}_t$ 的选择性**：$\mathbf{C}_t$ 决定了从隐状态中读取哪些信息作为输出。输入依赖的 $\mathbf{C}_t$ 使模型能够根据当前上下文动态调整输出的信息组合。

然而，参数的输入依赖性也带来了计算上的挑战：由于 $\overline{\mathbf{A}}_t$、$\overline{\mathbf{B}}_t$、$\mathbf{C}_t$ 在每个时间步都不同，S4中基于固定卷积核和FFT的高效并行计算方式不再适用——固定卷积核的前提是系统参数在所有时间步上保持一致，而Mamba的参数是时变的。为此，Mamba设计了**硬件感知的并行扫描算法**，将递推计算重构为并行前缀和运算，充分利用GPU的并行计算架构，同时采用核融合和重计算等技术优化GPU显存访问模式，在保持 $O(L)$ 理论复杂度的同时实现了接近卷积模式的实际运行速度。

[此处插入图：S4与Mamba的核心区别对比图。左侧为S4，A/B/C/Δ标注为"固定参数"（训练后不变），每个时间步使用相同的规则处理输入。右侧为Mamba，B/C/Δ标注为"由输入动态生成"，每个时间步根据输入内容使用不同的规则。用不同粗细的箭头示意不同时间步参数的变化。]

### 2.3.4 二维选择性扫描机制（SS2D）

Mamba最初为一维序列数据（如文本、语音）设计，将其应用于二维图像数据面临一个根本性挑战：图像具有天然的二维空间结构，像素之间在水平、垂直和对角线等多个方向上存在空间依赖关系，而SSM本质上是一维序列模型，只能沿单一方向进行递推扫描。

如果简单地采用逐行扫描（raster scan）将二维图像展开为一维序列，会产生一个严重问题：同一行内相邻像素之间的依赖关系可以被SSM直接建模（因为它们在序列中相邻），但不同行之间在垂直方向上相邻的像素在展开后的序列中相隔了整整一行的长度（即 $W$ 个位置）。虽然SSM理论上可以通过隐状态的逐步传递来捕获这种跨行依赖，但信息需要经过 $W$ 步才能从一个像素传递到其正下方的像素，传递效率低下且容易出现信息衰减。更严重的是，单一方向的扫描引入了方向性偏差——沿扫描方向上游的像素可以影响下游像素，但下游像素的信息无法反向传递给上游像素。

为解决这些问题，VMamba提出了**二维选择性扫描模块（2D Selective Scan, SS2D）**。SS2D的核心设计思想是：沿多个互补方向分别展开二维特征图为一维序列，对每个方向独立进行SSM扫描，最后将各方向的结果进行融合。通过多方向的协同扫描，确保特征图上任意两个位置之间都存在高效的信息传递路径。

具体而言，SS2D采用四个扫描方向：
- **方向1（左上→右下）**：逐行从左到右扫描，对应标准的行优先展开顺序。该方向能够有效捕获从左上区域向右下区域的空间依赖关系。
- **方向2（右下→左上）**：方向1的逆序扫描，使得右下区域的信息能够向左上区域传递，弥补方向1中信息只能单向流动的缺陷。
- **方向3（右上→左下）**：逐行从右到左扫描。该方向与方向1构成水平方向的互补，能够捕获从右上区域向左下区域的依赖关系。
- **方向4（左下→右上）**：方向3的逆序扫描，与方向3构成完整的双向覆盖。

[此处插入图：SS2D四方向扫描示意图。中间展示一个4×4的二维特征图网格，四周用四种不同颜色的箭头路径分别标注四个扫描方向。在图下方，展示每个方向将2D特征图展开为1D序列后通过SSM处理的过程。最后，展示四个方向的输出如何通过逐元素求和合并为最终输出。]

通过这种四方向交叉扫描策略，特征图上任意两个位置 $(i_1, j_1)$ 和 $(i_2, j_2)$ 之间至少存在两条扫描路径使信息可达（一条正向路径和一条反向路径）。以特征图左上角和右下角两个位置为例：方向1中，左上角的信息可以沿着扫描顺序传递到右下角；方向2中，右下角的信息可以沿逆序传递到左上角。这样，无论两个位置的空间关系如何，都能通过至少一个扫描方向实现高效的信息交互。

SS2D模块的完整处理流程如下：输入特征 $X \in \mathbb{R}^{B \times H \times W \times C}$ 首先通过线性投影扩展通道维度，然后分为两个并行分支。第一个分支经过深度可分离卷积提取局部特征后，执行四方向扫描——将特征图分别按四个方向展开为一维序列，对每个方向独立进行选择性SSM递推扫描，再将四个方向的输出合并（逐元素求和）。第二个分支经过SiLU激活函数，作为门控信号对扫描结果进行调制。两个分支的输出逐元素相乘后，通过线性投影恢复至原始通道维度，得到最终输出特征。整个过程的计算复杂度为 $O(H \times W)$，与特征图的像素数呈线性关系，远低于Transformer自注意力的 $O(H^2 \times W^2)$ 复杂度。

本文在DP-UNet的DVSS模块中采用SS2D作为共享基座，利用其高效的全局建模能力为后续的全局路径和局部路径提供共同的基础特征表示。

## 2.4 注意力机制

注意力机制是深度学习中一种重要的特征增强技术，其设计灵感源于人类视觉系统的选择性注意机制：在面对复杂场景时，人类视觉系统并非均匀地处理视野中的所有信息，而是将有限的注意资源集中在与当前任务最相关的区域或特征上。在深度学习中，注意力机制通过动态计算特征的重要性权重，使模型能够自适应地聚焦于最有价值的信息，抑制不相关或冗余的信息。

根据作用维度的不同，注意力机制可以分为通道注意力（关注"哪些特征通道更重要"）、空间注意力（关注"哪些空间位置更重要"）以及自注意力/交叉注意力（关注"哪些位置之间存在强关联"）等类型。本文在不同模块中分别采用了这三种注意力机制，下面逐一介绍其原理和实现。

### 2.4.1 通道注意力机制

在卷积神经网络中，每个卷积层的输出特征图包含多个通道，不同通道对应不同类型的特征响应——有的通道可能捕获了边缘信息，有的通道可能响应了颜色变化，有的通道可能检测了特定的纹理模式。然而，标准卷积操作对所有通道赋予相同的处理权重，并未区分不同通道的重要性差异。在实际任务中，并非所有通道的特征都同等重要：对于建筑物的分割，边缘和几何特征通道可能更为关键；对于植被的分割，颜色和纹理特征通道可能更为重要。通道注意力机制的目标正是让模型自动学习各通道的相对重要性，增强有用通道的权重、抑制不相关通道的干扰。

**SE（Squeeze-and-Excitation）注意力**是通道注意力的经典方法，通过"压缩"和"激励"两个阶段实现通道重标定。

**压缩（Squeeze）阶段**的目的是获取每个通道的全局信息摘要。对于一个 $H \times W \times C$ 的特征图，每个通道是一个 $H \times W$ 的二维特征响应图，包含了丰富的空间信息。为了评估该通道的整体重要性，需要将其二维空间信息压缩为一个标量。SE模块通过全局平均池化实现这一目标：

$$z_c = \frac{1}{H \times W}\sum_{i=1}^{H}\sum_{j=1}^{W} X_{i,j,c}$$

其中，$z_c$ 为第 $c$ 个通道的全局描述符。这一操作将每个通道的空间信息浓缩为其平均激活强度，得到一个 $C$ 维的通道描述向量 $z \in \mathbb{R}^{C}$。

**激励（Excitation）阶段**的目的是基于通道描述向量学习通道间的依赖关系，生成每个通道的重要性权重。SE模块通过一个瓶颈结构的全连接网络来实现：

$$s = \sigma(\mathbf{W}_2 \cdot \delta(\mathbf{W}_1 \cdot z))$$

其中，$\mathbf{W}_1 \in \mathbb{R}^{\frac{C}{r} \times C}$ 为降维投影矩阵，将 $C$ 维描述向量压缩为 $\frac{C}{r}$ 维（$r$ 为压缩比，通常取16），$\delta$ 为ReLU激活函数引入非线性，$\mathbf{W}_2 \in \mathbb{R}^{C \times \frac{C}{r}}$ 为升维投影矩阵，将特征恢复至 $C$ 维，$\sigma$ 为Sigmoid激活函数，将输出值约束在 $[0, 1]$ 范围内。最终，权重向量 $s$ 与输入特征图逐通道相乘：$\hat{X}_c = s_c \cdot X_c$，实现通道级别的特征重标定。

SE模块的降维操作虽然减少了参数量，但也带来了信息损失——$C$ 维的通道交互关系被压缩至 $\frac{C}{r}$ 维的瓶颈空间中，可能丢失部分通道间的细微依赖关系。此外，两层全连接网络引入的参数量为 $\frac{2C^2}{r}$，在通道数较大时仍有可观的计算开销。

**ECA（Efficient Channel Attention）注意力**针对SE模块的上述局限进行了轻量化改进，本文在DVSS模块的局部路径中采用ECA进行通道重标定。ECA的核心改进思想是：通道间的依赖关系实际上主要存在于相邻通道之间，而非所有通道之间都需要建模全局依赖。基于这一观察，ECA用一个核大小为 $k$ 的一维卷积替代了SE模块中的两层全连接网络：

$$s = \sigma(\text{Conv1D}_k(z))$$

其中，一维卷积核 $\text{Conv1D}_k$ 在通道维度上滑动，每个通道的权重仅由其邻域内 $k$ 个通道的描述符共同决定。卷积核大小 $k$ 可以根据通道数 $C$ 自适应确定：

$$k = \psi(C) = \left|\frac{\log_2 C}{\gamma} + \frac{b}{\gamma}\right|_{odd}$$

其中，$\gamma$ 和 $b$ 为超参数（通常取 $\gamma=2, b=1$），$|\cdot|_{odd}$ 表示取最近的奇数。这一公式的设计思想是：通道数越多，通道间的依赖范围可能越广，因此需要更大的卷积核。

[此处插入图：SE模块与ECA模块的结构对比图。左侧SE模块：输入特征图→全局平均池化→FC(C→C/r)→ReLU→FC(C/r→C)→Sigmoid→通道加权。右侧ECA模块：输入特征图→全局平均池化→1D Conv(kernel=k)→Sigmoid→通道加权。用红色标注ECA省略了全连接层的降维升维过程。]

与SE模块相比，ECA具有两个显著优势。第一，ECA避免了通道维度的降维操作，所有通道的信息在注意力计算过程中得以完整保留，不会因瓶颈压缩而丢失通道间的细微依赖关系。第二，一维卷积的参数量仅为 $k$（通常为3或5），远小于SE模块中两层全连接层的参数量 $\frac{2C^2}{r}$，计算开销大幅降低。本文选择ECA作为DVSS局部路径中的通道注意力模块，正是出于其在轻量化和信息保留之间的良好平衡。

### 2.4.2 空间注意力机制

通道注意力解决了"哪些特征通道更重要"的问题，但它对每个通道施加统一的权重标量，无法区分同一通道内不同空间位置的重要性差异。然而，在语义分割任务中，不同空间位置的重要性往往存在显著差异：目标区域（如建筑物、道路）的像素位置对分割结果至关重要，而背景区域的像素位置则相对不重要。空间注意力机制的目标是生成一个与输入特征图具有相同空间尺寸的权重图，使模型能够自适应地增强目标区域的特征响应、抑制背景区域的干扰。

空间注意力的核心问题是：如何从多通道特征图中推断出各空间位置的相对重要性。一种有效的方法是利用通道维度的统计信息来反映空间位置的显著程度——如果某个空间位置在多数通道上都具有较强的激活响应，则该位置很可能对应重要的目标区域。基于这一思想，空间注意力模块首先沿通道维度分别进行平均池化和最大池化：

$$X_{avg} = \frac{1}{C}\sum_{c=1}^{C} X_{:,:,c} \in \mathbb{R}^{H \times W \times 1}$$

$$X_{max} = \max_{c} X_{:,:,c} \in \mathbb{R}^{H \times W \times 1}$$

平均池化反映了每个空间位置上所有通道的平均响应强度——平均值较高的位置通常具有较为一致的多通道激活，表明该位置可能是重要的目标区域。最大池化则捕获了每个空间位置上最显著的单通道响应——最大值较高的位置通常包含至少一种强烈的特征响应，可能对应突出的边缘、纹理或目标区域。两种池化方式从不同角度提取空间位置的显著性信息，相互补充。

将两个描述符沿通道维度拼接为一个2通道的特征图，然后通过一个 $7 \times 7$ 的卷积层（较大的卷积核用于捕获空间位置之间的局部关系）和Sigmoid激活函数生成空间注意力图：

$$M_s = \sigma(f^{7 \times 7}([X_{avg}; X_{max}]))$$

最终，空间注意力图 $M_s \in \mathbb{R}^{H \times W \times 1}$ 通过广播机制与输入特征图逐元素相乘，实现对不同空间位置的差异化增强：

$$\hat{X} = M_s \odot X$$

本文在MSK模块中采用了上述空间注意力机制进行多尺度融合特征的空间增强。选择纯空间注意力而非通道-空间混合注意力的设计考量将在第三章方法部分详细阐述。

### 2.4.3 自注意力与交叉注意力机制

通道注意力和空间注意力都属于轻量级的特征重标定机制，它们通过为通道或空间位置分配权重来增强特征，但并未建模特征图中不同位置之间的显式关联关系。在许多场景中，理解位置间的长距离关联对于语义分割至关重要——例如，遥感图像中一条道路的不同部分虽然在空间上可能相距较远，但它们之间存在强烈的语义关联，模型需要将它们识别为同一类别。**自注意力机制**正是为建模这种位置间的全局关联关系而设计。

自注意力机制的核心思想是：对于序列中的每个位置，计算它与所有其他位置之间的相关性，然后根据相关性从全局范围内聚合最相关的信息。这一过程通过查询（Query）、键（Key）和值（Value）三组向量的交互来实现。

给定输入特征 $X \in \mathbb{R}^{N \times d}$（$N$ 为序列长度或图像中的像素数，$d$ 为特征维度），首先通过三个独立的线性投影将输入映射为三组向量：

$$Q = XW_Q, \quad K = XW_K, \quad V = XW_V$$

这三组向量的物理含义可以用"信息检索"的类比来理解：**查询 $Q$** 代表每个位置"想要什么信息"的需求描述；**键 $K$** 代表每个位置"拥有什么信息"的索引标签；**值 $V$** 代表每个位置实际存储的信息内容。注意力计算的过程就是每个位置用自己的查询去匹配所有位置的键，找到最相关的位置，然后从这些位置的值中提取信息。

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

这个公式可以分解为三个步骤理解。第一步，计算注意力分数矩阵 $QK^T \in \mathbb{R}^{N \times N}$，其中第 $(i, j)$ 个元素 $q_i \cdot k_j^T$ 表示第 $i$ 个位置的查询与第 $j$ 个位置的键之间的点积相似度——点积值越大，说明两个位置之间的关联性越强。第二步，除以缩放因子 $\sqrt{d_k}$。这一步的必要性在于：当特征维度 $d_k$ 较大时，点积的数值会随 $d_k$ 的增大而增大，导致Softmax函数的输入值过大，输出的概率分布趋于"尖锐"（即只关注少数几个位置），梯度趋于零，不利于训练。除以 $\sqrt{d_k}$ 可以将点积值的方差稳定在适当范围内。第三步，对缩放后的注意力分数应用Softmax函数进行归一化，使每个查询位置的注意力权重之和为1，形成概率分布。最后，用注意力权重对值向量 $V$ 进行加权求和，得到每个位置的输出——该输出是全局所有位置信息的加权聚合，权重由位置间的语义相关性决定。

在实际应用中，通常采用**多头注意力（Multi-Head Attention）** 机制。其动机是：单一的注意力计算只能学习一种类型的位置关联模式，而图像中的位置关联可能是多样的（如纹理相似性、几何邻近性、语义共属性等）。多头机制将输入特征沿通道维度划分为 $h$ 个子空间（头），在每个子空间中独立进行注意力计算：

$$\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)W_O$$

$$\text{head}_i = \text{Attention}(QW_Q^i, KW_K^i, VW_V^i)$$

每个头可以学习不同类型的关联模式，最后通过拼接和线性投影将多种模式的信息整合。

**交叉注意力机制（Cross-Attention）** 是自注意力的自然扩展，区别在于查询与键/值来自不同的输入源。在自注意力中，$Q$、$K$、$V$ 均由同一输入 $X$ 生成，建模的是单一序列内部各位置之间的关联。而在交叉注意力中，查询来自输入 $X_1$，键和值来自另一个输入 $X_2$：

$$Q = X_1 W_Q, \quad K = X_2 W_K, \quad V = X_2 W_V$$

$$\text{CrossAttn}(X_1, X_2) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

交叉注意力的物理含义可以理解为：以 $X_1$ 的特征作为"需求方"，从 $X_2$ 的特征中"按需检索"最相关的信息。对于多模态融合任务而言，这种机制尤为适用——例如，以光学图像的特征作为查询，从SAR图像的特征中检索与光学特征语义最匹配的互补信息。与简单的特征拼接或逐元素相加相比，交叉注意力能够根据内容的语义相关性进行精细化的信息选取，避免无关或冲突信息的引入。本文在多模态融合网络的CrossModalMSK模块中正是采用交叉注意力机制来实现光学与SAR特征之间的跨模态信息交互。

## 2.5 多模态遥感数据特性

本文的第二项工作涉及光学图像与SAR图像的多模态融合分割。两种模态的遥感数据在成像原理上存在本质差异，充分理解各自的数据特性和互补关系，是设计有效融合策略的前提。

### 2.5.1 光学遥感图像

光学遥感图像通过被动接收地表反射或辐射的可见光及近红外波段电磁波进行成像。其工作原理与人眼类似：太阳光照射地表后，不同地物类型的表面材质会对不同波长的光产生差异化的反射，传感器接收这些反射光并转化为数字图像。正是这种波长选择性反射特性，赋予了光学图像丰富的光谱信息——例如，健康植被在近红外波段反射率极高而在红色波段反射率较低，水体在近红外波段几乎完全吸收而在蓝色波段反射率较高，建筑物的反射率则在各波段上都较为均匀。通过多波段的光谱组合和比值分析，可以有效区分不同的地物类型。

除光谱信息外，高分辨率光学图像还能提供清晰的空间纹理和视觉边缘信息，使得地物的形状、结构和空间关系一目了然。这些特性使光学图像成为遥感应用中使用最广泛的数据源。

然而，光学遥感成像的被动工作方式也带来了固有的局限性。第一，光学成像依赖太阳光照射，因此只能在白天进行数据采集，夜间无法成像。第二，可见光和近红外波段的电磁波无法穿透云层、雾霾和浓烟，当目标区域被云层覆盖时，光学传感器获取的图像中被遮挡区域完全无法获取有效的地表信息。在多云多雨的热带和亚热带地区，获取无云光学图像的窗口期十分有限，严重制约了光学遥感数据的时效性。第三，光学图像对光照角度和强度变化敏感，建筑物和树木的阴影区域、高光反射区域等都会干扰地物的正常光谱表现，导致同一地物在不同光照条件下呈现截然不同的影像特征，给分割模型的稳定性带来挑战。

### 2.5.2 SAR遥感图像

合成孔径雷达（SAR）是一种主动微波遥感传感器，其工作原理与光学传感器截然不同：SAR自身发射微波脉冲信号照射地表，然后接收地表反射回来的回波信号，通过对回波信号进行处理和分析生成地表图像。SAR的工作波段为微波波段（波长通常在厘米至分米量级），远长于光学波段（波长在纳米量级）。

SAR最突出的优势在于其**全天候、全天时**的成像能力。由于微波波长远大于云层水滴和雾霾颗粒的尺寸，微波可以穿透云层、雨雾和轻度烟尘等大气遮挡物而几乎不发生衰减。同时，SAR自身发射微波脉冲，不依赖太阳光照，因此可以在白天和夜间任何时间进行成像。这一特性使SAR在光学传感器无法工作的恶劣天气条件下仍然能够提供有效的地表观测数据，在洪水灾害监测、地震灾情评估等需要快速响应的应急场景中具有不可替代的价值。

SAR图像的灰度值反映的是地表对微波的后向散射强度，与地物的物理和几何特性密切相关。影响后向散射强度的主要因素包括：地物表面的介电常数（含水量越高，散射越强）、表面粗糙度（粗糙表面产生更强的散射）、地物的几何形状（垂直墙面和金属结构会产生强烈的角反射）以及微波的入射角度。因此，SAR图像能够提供光学图像无法获取的地表物理结构信息。

然而，SAR图像也面临若干固有的挑战。首先，**相干斑噪声**是SAR图像最显著的问题。相干斑噪声由微波的相干干涉效应产生——当微波照射粗糙表面时，来自不同散射体的回波信号之间发生相干叠加，产生随机的增强和抵消效应，在图像中表现为颗粒状的明暗斑点。相干斑噪声的存在严重降低了SAR图像的视觉质量，使得地物的边界和纹理信息被噪声掩盖，大大增加了自动化解译的难度。其次，SAR图像缺乏光学图像中的光谱信息。标准的单极化SAR图像仅包含一个通道的散射强度信息，无法像多波段光学图像那样通过光谱差异来区分地物类型，导致对某些光谱特性差异显著但散射特性相似的地物（如不同作物类型）区分能力有限。

[此处插入图：光学图像与SAR图像对比示意图。选取WHU-OPT-SAR数据集中的同一区域，左侧展示光学图像（RGB合成），右侧展示SAR图像（灰度），下方展示语义标注图。标注两种图像在视觉表现上的差异：光学图像色彩丰富、纹理清晰，SAR图像噪声明显但建筑结构突出。]

### 2.5.3 多模态互补性分析

从上述分析可以看出，光学图像和SAR图像在信息维度上具有天然的互补性，如表2-1所示。

[此处插入表格：表2-1 光学图像与SAR图像特性对比]

| 特性 | 光学图像 | SAR图像 |
|------|---------|---------|
| 成像方式 | 被动接收反射光 | 主动发射微波脉冲 |
| 工作波段 | 可见光、近红外 | 微波（L/C/X波段） |
| 成像条件 | 依赖日照，受云雨影响 | 全天候、全天时 |
| 信息类型 | 光谱反射特性 | 后向散射特性 |
| 优势 | 光谱丰富、纹理清晰 | 穿透云层、结构信息 |
| 局限 | 云遮挡、光照敏感 | 相干斑噪声、缺乏光谱 |

通过融合两种模态的互补信息，可以在多个方面实现优势互补。在数据可用性方面，当光学图像因云层覆盖而无法提供有效信息时，SAR数据可以填补信息缺口，确保地表观测的连续性。在地物区分能力方面，光学图像丰富的光谱信息可以增强SAR数据有限的类别判别能力，而SAR图像的几何结构信息可以辅助光学图像在阴影区域和光照不均匀区域的地物识别。在特征表达方面，融合两种模态能够从光谱、纹理、结构等多个维度全面表征地物特征，提供比任何单一模态更完整的信息。

然而，两种模态在数据特性上的巨大差异也给融合带来了显著挑战。首先，两种模态的通道数不同——光学图像通常包含3或4个通道（RGB或RGBNIR），SAR图像通常为单通道。其次，两种模态的值域分布差异显著，光学图像的像素值通常为0-255的正整数，SAR图像的散射强度可能以分贝为单位表示，包含负值且动态范围不同。此外，两种模态的噪声特性完全不同——光学图像主要受高斯噪声影响，SAR图像则受乘性的相干斑噪声影响。这些异质性要求融合算法能够有效地弥合模态鸿沟，在保持各模态特异性特征的同时实现深层次的语义对齐和信息互补。

## 2.6 数据集与评价指标

### 2.6.1 ISPRS Potsdam数据集

ISPRS Potsdam数据集由国际摄影测量与遥感学会（ISPRS）提供，是遥感图像语义分割领域广泛使用的标准基准数据集之一。该数据集覆盖德国波茨坦市的城市区域，以其高分辨率和精细标注著称。数据集包含38幅6000×6000像素的航空正射影像，地面采样距离（Ground Sample Distance, GSD）为5厘米。每幅图像包含近红外（NIR）、红色（R）和绿色（G）三个通道（NIRRG），同时提供对应的数字表面模型（DSM）数据。数据集标注了6个语义类别：不透水面（Impervious Surface）、建筑物（Building）、低矮植被（Low Vegetation）、树木（Tree）、车辆（Car）和背景/杂波（Clutter/Background），在评价时通常只计算前5个类别的指标。

Potsdam数据集的主要挑战在于：第一，城市场景中不同类别的地物紧密交织，建筑物与不透水面的光谱特征高度相似，容易产生混淆；第二，车辆目标尺度较小，仅占图像中极少的像素比例，对模型的小目标检测能力提出了较高要求；第三，树木和低矮植被虽然同属植被类别，但需要被区分为两个独立的类别，要求模型能够捕获植被类内的细微差异。

在本文实验中，按照常用的实验设置，选取23幅图像用于训练（排除标注存在错误的第710号图像），14幅图像用于测试。训练和测试时，将原始图像裁剪为512×512像素的小块进行处理。

[此处插入图：ISPRS Potsdam数据集样例。展示2-3组样例，每组包含NIRRG正射影像和对应的语义标注图（不同颜色代表不同类别）。附图例说明各颜色对应的地物类别。]

### 2.6.2 ISPRS Vaihingen数据集

ISPRS Vaihingen数据集同样由ISPRS提供，覆盖德国Vaihingen城市区域。该数据集包含33幅高分辨率航空正射影像，图像大小不一（平均约2494×2064像素），GSD为9厘米。每幅图像同样包含NIRRG三个通道和对应的DSM数据。语义类别与Potsdam数据集完全一致，包含不透水面、建筑物、低矮植被、树木、车辆和背景/杂波共6个类别。

与Potsdam数据集相比，Vaihingen数据集的GSD稍大（9厘米 vs 5厘米），意味着每个像素覆盖的地面面积更大，图像中地物的细节信息相对较少。此外，Vaihingen的城市建筑密度较高，建筑物之间的间距较小，阴影遮挡现象更为显著，增加了建筑物边界提取和阴影区域地物识别的难度。同时，Vaihingen的总数据量较Potsdam更少，对模型在有限训练数据条件下的泛化能力提出了更高要求。这些差异使得Vaihingen数据集成为评估模型跨场景泛化能力的有价值补充。

在本文实验中，按照常用的划分方式，选取部分图像用于训练，其余用于测试。

[此处插入图：ISPRS Vaihingen数据集样例。格式同Potsdam。]

### 2.6.3 LoveDA数据集

LoveDA数据集是一个面向领域自适应研究的大规模遥感图像语义分割数据集，覆盖中国南京、常州和武汉三个城市的城市和乡村区域。该数据集包含5987幅1024×1024像素的高分辨率遥感图像，GSD为0.3米，每幅图像包含红色（R）、绿色（G）和蓝色（B）三个通道。数据集标注了7个语义类别：背景（Background）、建筑物（Building）、道路（Road）、水体（Water）、裸地（Barren）、森林（Forest）和农田（Agriculture）。

LoveDA数据集相比Potsdam和Vaihingen数据集具有两个显著特点。第一，场景多样性更强。LoveDA同时包含城市和乡村两种差异显著的场景类型：城市场景中建筑物密集、道路网络复杂、地物尺度较小但种类丰富；乡村场景中农田和森林面积广阔、地物边界模糊、类间特征差异较小（如农田和裸地在某些季节光谱特征高度相似）。第二，类别不平衡更严重。不同类别的像素比例差异悬殊，背景类可能占据大量像素，而裸地等少数类的像素比例极低，这对损失函数的设计和模型对少数类的学习能力提出了更高要求。

这些特点使LoveDA成为评估模型在复杂多变场景下综合分割能力的重要基准。在本文实验中，按照官方划分进行训练和测试。

[此处插入图：LoveDA数据集样例。展示城市和乡村各1-2组样例，包含RGB影像和对应标注图。]

### 2.6.4 WHU-OPT-SAR数据集

WHU-OPT-SAR数据集是一个专为光学与SAR图像融合语义分割任务设计的大规模多模态遥感数据集，由武汉大学构建并公开发布。该数据集覆盖中国湖北省约50000平方公里的区域（30°N-33°N，108°E-117°E），地形涵盖了山地、林地、丘陵、平原等多种复杂类型，植被包括针叶林、阔叶林、灌木和水生植被等多种种类，为多模态融合分割方法的评估提供了地理和生态条件丰富的实验基础。

数据集中的光学图像由高分一号（GF-1）卫星采集，包含红色（R）、绿色（G）、蓝色（B）和近红外（NIR）四个通道，原始地面分辨率为2米。SAR图像由高分三号（GF-3）卫星采集，为单通道极化图像，地面分辨率为5米。为实现两种模态图像之间的逐像素空间对应，光学图像通过双线性插值重采样至5米分辨率，并在WGS-84坐标系下与SAR图像进行精确的几何配准。数据集共包含100幅5556×3704像素的配准光学-SAR图像对，提供像素级语义标注，包含7个类别：背景（Background）、农田（Farmland）、城市（City）、村庄（Village）、水体（Water）、森林（Forest）和道路（Road）。

WHU-OPT-SAR数据集是目前公开可用的最大规模光学-SAR融合语义分割数据集。相比前三个单模态数据集，WHU-OPT-SAR的核心挑战在于：第一，光学图像和SAR图像在成像机理上的本质差异导致同一地物在两种模态中呈现截然不同的外观，模型需要学会跨越模态鸿沟提取互补信息；第二，SAR图像中固有的相干斑噪声可能在融合过程中干扰光学特征的判别性，要求融合策略具有一定的噪声鲁棒性；第三，数据集覆盖的地理范围广、地形和植被种类多样，对模型的泛化能力提出了较高要求。

在本文实验中，将原始图像裁剪为固定大小的图像块，按照训练集、验证集和测试集进行划分。

[此处插入图：WHU-OPT-SAR数据集样例。展示2-3组样例，每组包含光学图像（RGB或RGBNIR合成）、对应的SAR图像（灰度）和语义标注图。直观展示同一区域在光学和SAR两种模态下的显著差异。]

### 2.6.5 评价指标

为全面评估语义分割模型的性能，本文采用以下评价指标。各指标均基于混淆矩阵进行计算，混淆矩阵是评估分类和分割模型的基础工具。对于包含 $K$ 个类别的语义分割任务，混淆矩阵 $\mathbf{M} \in \mathbb{R}^{K \times K}$ 中的元素 $M_{ij}$ 表示真实类别为 $i$ 且被预测为类别 $j$ 的像素数量。对角线元素 $M_{ii}$ 代表正确分割的像素数量，非对角线元素 $M_{ij}$（$i \neq j$）反映了类别 $i$ 被误判为类别 $j$ 的像素数量。

**（1）总体精度（Overall Accuracy, OA）**

总体精度衡量的是所有像素中被正确分类的比例，是最直观的整体性能指标：

$$OA = \frac{\sum_{i=0}^{K-1} M_{ii}}{\sum_{i=0}^{K-1}\sum_{j=0}^{K-1} M_{ij}}$$

其中，分子为混淆矩阵对角线元素之和（正确分类的总像素数），分母为所有元素之和（总像素数）。OA直观易懂，但在类别像素分布不均衡时可能具有误导性——例如，当背景类占据90%的像素时，即使模型将所有像素都预测为背景，OA也可达到90%，但实际分割效果极差。因此，OA通常需要与其他指标结合使用。

**（2）交并比与平均交并比（IoU / mIoU）**

交并比（Intersection over Union, IoU）是语义分割中最核心的类别级评价指标。对于某一类别 $i$，IoU衡量的是模型预测为该类别的区域与真实属于该类别的区域之间的重叠程度：

$$IoU_i = \frac{M_{ii}}{\sum_{j=0}^{K-1} M_{ij} + \sum_{j=0}^{K-1} M_{ji} - M_{ii}}$$

分子 $M_{ii}$ 为预测正确的像素数，即预测区域与真实区域的交集。分母包含三项：$\sum_{j} M_{ij}$ 为真实属于类别 $i$ 的总像素数（真实区域面积），$\sum_{j} M_{ji}$ 为被预测为类别 $i$ 的总像素数（预测区域面积），减去 $M_{ii}$ 避免交集被重复计算，最终得到预测区域与真实区域的并集。IoU的取值范围为 $[0, 1]$，值越接近1表示预测区域与真实区域的重叠度越高，分割效果越好。

平均交并比（mIoU）是所有类别IoU的算术平均值：

$$mIoU = \frac{1}{K}\sum_{i=0}^{K-1} IoU_i$$

mIoU对每个类别赋予相同的权重，不受类别像素数量不平衡的影响。即使某一少数类仅占图像的极小比例，其IoU对mIoU的贡献权重与多数类完全相同。这一特性使mIoU成为语义分割任务中最被广泛认可和使用的综合评价指标。

**（3）F1分数与平均F1分数（F1 / mF1）**

F1分数是精确率（Precision）和召回率（Recall）的调和平均值，从分类的角度综合评估模型的准确性和完整性。对于类别 $i$：

$$Precision_i = \frac{M_{ii}}{\sum_{j=0}^{K-1} M_{ji}}, \quad Recall_i = \frac{M_{ii}}{\sum_{j=0}^{K-1} M_{ij}}$$

精确率 $Precision_i$ 反映了模型预测为类别 $i$ 的像素中真正属于该类别的比例，即"预测的准不准"——高精确率意味着低误检率。召回率 $Recall_i$ 反映了真实属于类别 $i$ 的像素中被模型成功检出的比例，即"找得全不全"——高召回率意味着低漏检率。F1分数平衡了两者的影响：

$$F1_i = \frac{2 \times Precision_i \times Recall_i}{Precision_i + Recall_i}$$

使用调和平均而非算术平均的原因在于：调和平均对极端值更为敏感——当精确率或召回率中任一项极低时，F1分数都会显著降低，从而避免了一项指标极高而另一项极低时给出误导性的高评分。平均F1分数（mF1）为所有类别F1的算术平均值。

**（4）计算效率指标**

除分割精度指标外，本文还采用以下指标全面评估模型的计算效率：

- **参数量（Parameters, Params）**：模型中所有可学习参数的总数，以百万（M）为单位。参数量反映了模型的存储需求和过拟合风险——参数量越大，模型的表达能力通常越强，但对训练数据量的需求也越大，且存储和传输成本更高。
- **浮点运算量（Floating Point Operations, FLOPs）**：模型进行一次前向推理所需的浮点乘加运算次数，以十亿次（G）为单位。FLOPs反映了模型的理论计算复杂度，是评估模型计算效率的重要指标。需要注意的是，FLOPs不完全等同于实际运行时间，后者还受到硬件架构、内存访问模式和算子并行度等因素的影响。
- **推理速度（Frames Per Second, FPS）**：模型在特定硬件上每秒能够处理的图像数量，以帧/秒（fps）为单位。FPS是最直接反映模型实际部署效率的指标，综合了计算复杂度、内存访问效率和硬件利用率等因素。

## 2.7 本章小结

本章系统介绍了本文研究工作所涉及的相关理论与技术基础。首先，阐述了语义分割任务的基本概念，分析了编码器-解码器架构如何通过层次化特征提取、渐进式空间恢复和跳跃连接来协调语义理解与空间定位之间的矛盾，并介绍了交叉熵损失和Dice损失各自的优势与不足及联合使用的合理性。其次，详细介绍了状态空间模型的理论基础，从连续SSM的状态方程和观测方程出发，阐述了离散化过程中递推模式与卷积模式的双重计算视角，分析了从S4的固定参数设计到Mamba的输入依赖选择性机制的关键技术跨越，并介绍了SS2D如何通过四方向交叉扫描将一维SSM的全局建模能力扩展到二维图像处理中。然后，分别介绍了SE和ECA通道注意力、空间注意力以及自注意力和交叉注意力等本文涉及的关键注意力机制，分析了各自的设计动机、数学原理和适用场景。接着，从成像原理层面分析了光学遥感图像和SAR遥感图像各自的数据特性、优势与固有局限，并系统讨论了两种模态之间的互补性和融合挑战。最后，详细介绍了ISPRS Potsdam、ISPRS Vaihingen、LoveDA和WHU-OPT-SAR四个公开数据集的基本信息、数据特点和实验划分，以及mIoU、OA、mF1等分割精度指标和参数量、FLOPs、FPS等计算效率指标的数学定义与物理含义。本章的内容为后续第三章和第四章的方法设计与实验分析提供了完整的理论支撑和实验基础。



短版本：

---

# 第二章 相关理论与技术基础

## 2.1 引言

本文的研究工作主要基于状态空间模型和注意力机制等深度学习方法，在单模态和多模态遥感图像语义分割领域展开。为建立后续研究的理论基础，本章将系统介绍相关的核心理论与关键技术。首先，阐述语义分割任务的基本概念、编码器-解码器架构和损失函数；其次，详细介绍状态空间模型的数学基础及其从S4到Mamba的技术演进；然后，介绍本文涉及的注意力机制；接着，分析光学与SAR遥感数据的特性及互补关系；随后，介绍本文实验所采用的数据集和评价指标；最后，对本章内容进行小结。

## 2.2 语义分割基础

### 2.2.1 语义分割任务概述

语义分割是计算机视觉领域中像素级理解任务的核心代表，其目标是对输入图像中的每一个像素赋予一个语义类别标签。形式化地，给定一幅输入图像 $I \in \mathbb{R}^{H \times W \times C}$，语义分割的目标是学习一个映射函数 $f$，将输入图像映射为一幅标签图 $Y \in \{0, 1, \ldots, K-1\}^{H \times W}$，其中 $K$ 为类别总数。

与图像分类仅需输出整幅图像的类别不同，语义分割要求模型同时完成语义理解（确定"是什么类别"）和空间定位（确定"在什么位置"）两个目标。这两个目标之间存在内在张力：获取高层语义信息需要通过下采样扩大感受野，但下采样会不可避免地损失空间位置精度。这一矛盾构成了语义分割方法设计的核心挑战，也是编码器-解码器架构被提出的根本动机。

在遥感图像中，这一挑战尤为突出。遥感图像分辨率高、覆盖面积大，地物尺度差异显著（从数百米的农田到数米的车辆），且不同类别之间存在"同物异谱"和"异物同谱"现象，对模型的多尺度建模能力和计算效率均提出了极高要求。

### 2.2.2 编码器-解码器架构

编码器-解码器架构是当前语义分割最主流的网络设计范式，其核心思想是将语义理解和空间恢复分别交由两个阶段完成。

**编码器**负责从输入图像中逐层提取层次化特征。以本文采用的ResNet-18为例，编码器由四个残差阶段组成，每个阶段通过卷积和下采样将特征图的空间分辨率降低一半、通道数增加一倍，依次输出 $\frac{H}{4} \times \frac{W}{4} \times 64$、$\frac{H}{8} \times \frac{W}{8} \times 128$、$\frac{H}{16} \times \frac{W}{16} \times 256$、$\frac{H}{32} \times \frac{W}{32} \times 512$ 四个层级的特征图。浅层特征保留了丰富的边缘和纹理等空间细节，深层特征则具有较强的语义抽象能力但空间细节已大量丢失。

**解码器**负责将编码器输出的低分辨率高语义特征逐步恢复至原始分辨率。由于仅靠上采样无法恢复编码过程中丢失的空间细节，编码器-解码器架构引入了**跳跃连接**机制：将编码器各层的高分辨率特征直接传递至解码器的对应层，使解码器在恢复空间细节时能够利用编码器保留的精确位置信息。通常的做法是将编码器特征与解码器上采样后的特征进行拼接或相加，再通过卷积操作融合两者的信息。

[此处插入图：编码器-解码器架构示意图（U形结构）。左侧编码器逐层下采样，右侧解码器逐层上采样，中间水平箭头表示跳跃连接。各层标注特征图尺寸和通道数。]

本文提出的DP-UNet即采用这一架构，以ResNet-18作为编码器骨干，以DVSS模块构建解码器，并通过MSK模块增强跳跃连接处的多尺度特征融合。

### 2.2.3 损失函数

损失函数用于量化模型预测与真实标签之间的差异，驱动模型参数的优化。本文采用交叉熵损失与Dice损失的联合损失。

**交叉熵损失**对每个像素独立计算预测概率分布与真实标签之间的差异：

$$\mathcal{L}_{CE} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{k=0}^{K-1} y_{i,k} \log(\hat{y}_{i,k})$$

其中，$N$ 为像素总数，$y_{i,k}$ 为第 $i$ 个像素真实标签的独热编码，$\hat{y}_{i,k}$ 为模型预测的类别概率。交叉熵损失提供了稳定的逐像素梯度信号，有利于训练初期的快速收敛。然而，当不同类别的像素数量严重不平衡时，多数类对总损失的贡献占据主导，导致模型忽视少数类的分割质量。

**Dice损失**从区域重叠的角度评估分割质量，对类别不平衡具有较好的鲁棒性：

$$\mathcal{L}_{Dice} = 1 - \frac{2\sum_{i=1}^{N} y_i \hat{y}_i + \epsilon}{\sum_{i=1}^{N} y_i + \sum_{i=1}^{N} \hat{y}_i + \epsilon}$$

其中，$y_i$ 为真实标签，$\hat{y}_i$ 为预测概率，$\epsilon$ 为防止分母为零的平滑因子。Dice损失关注预测区域与真实区域的相对重叠比例而非绝对像素数量，即使少数类的像素数量很少，只要分割不准确，损失值就会显著增大，从而给予少数类更大的优化权重。

本文采用两者的联合损失 $\mathcal{L} = \mathcal{L}_{CE} + \mathcal{L}_{Dice}$，兼顾逐像素梯度的稳定性和区域级别的类别平衡性。

## 2.3 状态空间模型

状态空间模型是本文DVSS模块中SS2D基座的核心理论基础。本节从SSM的数学定义出发，阐述其离散化过程，分析从S4到Mamba的关键技术突破，最后介绍将一维SSM扩展到二维图像的SS2D机制。

### 2.3.1 连续状态空间模型与离散化

状态空间模型起源于控制理论，通过隐状态的线性动力学方程描述输入到输出的映射关系。连续时间SSM由状态方程和观测方程定义：

$$h'(t) = \mathbf{A}h(t) + \mathbf{B}x(t)$$

$$y(t) = \mathbf{C}h(t)$$

其中，$x(t) \in \mathbb{R}$ 为输入，$y(t) \in \mathbb{R}$ 为输出，$h(t) \in \mathbb{R}^{N}$ 为 $N$ 维隐状态向量。状态转移矩阵 $\mathbf{A} \in \mathbb{R}^{N \times N}$ 控制隐状态自身的演化规律，决定了历史信息在传递过程中如何被保留和衰减；输入矩阵 $\mathbf{B} \in \mathbb{R}^{N \times 1}$ 控制输入信号如何被写入隐状态；输出矩阵 $\mathbf{C} \in \mathbb{R}^{1 \times N}$ 决定从隐状态中读取哪些信息作为输出。

SSM的核心优势在于：隐状态 $h(t)$ 通过线性递推逐步积累全局信息，无需像自注意力机制那样显式计算所有位置对之间的关系，因此计算复杂度与序列长度呈线性关系。

由于深度学习中的数据为离散序列，需引入步长参数 $\Delta$ 将连续SSM离散化。采用零阶保持（ZOH）方法，离散化后的系统方程为：

$$h_t = \overline{\mathbf{A}} h_{t-1} + \overline{\mathbf{B}} x_t, \quad y_t = \mathbf{C} h_t$$

其中，$\overline{\mathbf{A}} = \exp(\Delta \mathbf{A})$，$\overline{\mathbf{B}} = (\Delta \mathbf{A})^{-1}(\exp(\Delta \mathbf{A}) - \mathbf{I}) \cdot \Delta \mathbf{B}$。该递推公式表明，每个时间步的隐状态由前一时刻隐状态经 $\overline{\mathbf{A}}$ 变换后保留的历史信息，与当前输入经 $\overline{\mathbf{B}}$ 编码后注入的新信息叠加而成。

离散SSM的一个重要特性是同时具备递推和卷积两种等价计算模式。将递推公式展开，输出序列可表示为输入序列与卷积核 $\overline{\mathbf{K}}$ 的卷积：

$$\overline{\mathbf{K}} = (\mathbf{C}\overline{\mathbf{B}}, \mathbf{C}\overline{\mathbf{A}}\overline{\mathbf{B}}, \mathbf{C}\overline{\mathbf{A}}^2\overline{\mathbf{B}}, \ldots, \mathbf{C}\overline{\mathbf{A}}^{L-1}\overline{\mathbf{B}})$$

$$y = x * \overline{\mathbf{K}}$$

卷积模式可利用快速傅里叶变换在 $O(L \log L)$ 时间内并行计算，适合训练阶段；递推模式的复杂度为 $O(L)$，适合推理阶段的高效自回归生成。两种模式的并存是SSM相比Transformer和RNN的独特优势。

### 2.3.2 从S4到Mamba：选择性机制的引入

**S4** 是Gu等人于2022年提出的结构化状态空间模型，首次将SSM成功应用于深度学习的长序列建模任务。S4的主要贡献在于解决了SSM在实际训练中的两个技术障碍：一是通过HiPPO初始化策略为状态转移矩阵 $\mathbf{A}$ 提供了最优的初始结构，使隐状态能够有效压缩和记忆历史输入信息；二是通过将 $\mathbf{A}$ 参数化为对角加低秩的特殊结构，利用频域变换将计算复杂度降至 $O(L \log L)$。S4在Long Range Arena等长序列基准上取得了突破性成果。

然而，S4有一个根本性局限：其参数 $\mathbf{A}$、$\mathbf{B}$、$\mathbf{C}$、$\Delta$ 在训练完成后即固定不变，对所有输入使用相同的状态转移规则。这种**线性时不变**（LTI）特性意味着模型无法根据输入内容自适应地调整信息的保留和遗忘策略——无论当前输入是重要的地物特征还是无关的背景噪声，模型都以完全相同的方式处理。

**Mamba** 是Gu和Dao于2023年提出的选择性状态空间模型，通过将S4的固定参数升级为输入依赖的动态参数，从根本上解决了LTI的局限。Mamba的核心创新——**选择性机制**——将 $\mathbf{B}$、$\mathbf{C}$ 和 $\Delta$ 参数化为输入的函数：

$$\mathbf{B}_t = s_B(x_t), \quad \mathbf{C}_t = s_C(x_t), \quad \Delta_t = \text{softplus}(s_\Delta(x_t))$$

其中，$s_B$、$s_C$、$s_\Delta$ 为可学习的线性投影。通过这种输入依赖的参数化，模型获得了内容感知的选择性处理能力：当遇到重要输入时，模型可以增大 $\Delta_t$ 使当前输入被强力写入隐状态；当遇到不相关输入时，减小 $\Delta_t$ 使隐状态几乎不受影响而保持先前的记忆。这种机制赋予了SSM类似于注意力机制的内容感知能力，但计算方式仍保持线性递推。

然而，输入依赖的参数使得S4中基于固定卷积核的FFT并行计算不再适用。为此，Mamba设计了硬件感知的并行扫描算法，将递推计算重构为并行前缀和运算，配合核融合和重计算等GPU优化技术，在保持 $O(L)$ 理论复杂度的同时实现了高效的实际运行速度。

[此处插入图：S4与Mamba对比图。左侧S4：A/B/C/Δ标注为固定参数。右侧Mamba：B/C/Δ由输入x动态生成（用箭头从输入指向参数），标注"选择性机制"。]

### 2.3.3 二维选择性扫描机制（SS2D）

Mamba最初为一维序列设计，将其应用于二维图像面临一个关键问题：如何将二维空间关系有效编码为一维序列。如果简单地逐行扫描，同一行内的像素依赖可以直接建模，但垂直方向相邻的像素在序列中相隔一整行的长度，信息传递效率低下。更严重的是，单一方向的扫描引入方向性偏差——信息只能从上游向下游传递，无法反向流动。

VMamba提出的二维选择性扫描模块（SS2D）通过**四方向交叉扫描**解决了这一问题。SS2D沿四个方向（左上→右下、右下→左上、右上→左下、左下→右上）分别将二维特征图展开为一维序列，对每个方向独立进行选择性SSM扫描，最后将四个方向的输出合并。

[此处插入图：SS2D四方向扫描示意图。展示二维特征图上四种颜色箭头标注的四个扫描方向。右侧展示各方向展开、SSM处理、合并的流程。]

这种设计确保了特征图上任意两个位置之间至少存在两条扫描路径使信息可达，从而在保持线性复杂度 $O(H \times W)$ 的同时实现了对二维空间全局依赖关系的建模。

SS2D模块的完整处理流程为：输入特征 $X \in \mathbb{R}^{B \times H \times W \times C}$ 经线性投影扩展通道后分为两个分支。第一个分支经深度可分离卷积和SiLU激活后执行四方向扫描，四个方向的输出逐元素求和合并；第二个分支经SiLU激活作为门控信号。两分支逐元素相乘后经线性投影恢复原始通道维度。本文在DVSS模块中将SS2D作为共享基座，为全局路径和局部路径提供共同的基础特征。

## 2.4 注意力机制

注意力机制通过动态计算特征的重要性权重，使模型能够自适应地聚焦于最有价值的信息。本文在不同模块中分别采用了通道注意力、空间注意力和交叉注意力三种机制。

### 2.4.1 通道注意力机制

卷积层输出的不同通道对应不同类型的特征响应，但标准卷积对所有通道赋予相同权重，未区分其重要性差异。通道注意力机制旨在自适应地学习各通道的重要性权重。

**SE（Squeeze-and-Excitation）模块**是通道注意力的经典方法。其核心流程为：首先通过全局平均池化将每个通道的空间信息压缩为一个标量，得到通道描述符 $z \in \mathbb{R}^{C}$；然后通过两层全连接网络（先降维至 $C/r$，再升维至 $C$，$r$ 为压缩比）学习通道间的依赖关系，输出通道权重 $s \in \mathbb{R}^{C}$：

$$z_c = \frac{1}{H \times W}\sum_{i=1}^{H}\sum_{j=1}^{W} X_{i,j,c}$$

$$s = \sigma(\mathbf{W}_2 \cdot \delta(\mathbf{W}_1 \cdot z))$$

其中，$\delta$ 为ReLU激活函数，$\sigma$ 为Sigmoid激活函数。最终，权重 $s$ 与输入特征逐通道相乘实现通道重标定。SE模块通过显式建模通道间依赖关系有效增强了特征判别性，但其降维操作可能丢失部分通道间的细微依赖，且两层全连接引入的参数量为 $\frac{2C^2}{r}$。

**ECA（Efficient Channel Attention）模块**针对SE的上述局限进行了轻量化改进，本文在DVSS模块的局部路径中采用ECA进行通道重标定。ECA的核心改进在于：用一个核大小为 $k$ 的一维卷积替代SE中的两层全连接网络，直接在相邻通道之间建模局部依赖关系：

$$s = \sigma(\text{Conv1D}_k(z))$$

卷积核大小 $k$ 根据通道数 $C$ 自适应确定：$k = \psi(C) = |\frac{\log_2 C}{\gamma} + \frac{b}{\gamma}|_{odd}$，其中 $\gamma$ 和 $b$ 为超参数，$|\cdot|_{odd}$ 取最近奇数。与SE相比，ECA有两个优势：一是避免了降维操作，所有通道信息完整保留；二是参数量仅为 $k$（通常为3或5），远小于SE的 $\frac{2C^2}{r}$。

[此处插入图：SE与ECA对比图。左侧SE：GAP→FC降维→ReLU→FC升维→Sigmoid→通道加权。右侧ECA：GAP→1D Conv→Sigmoid→通道加权。标注ECA用轻量1D卷积替代了全连接层。]

### 2.4.2 空间注意力机制

与通道注意力关注"哪些通道更重要"不同，空间注意力关注"哪些空间位置更重要"。在语义分割中，目标区域的像素位置比背景区域更重要，空间注意力通过生成空间权重图来增强目标区域、抑制背景干扰。

本文在MSK模块中采用的空间注意力实现方式如下：首先沿通道维度分别进行平均池化和最大池化，得到两个单通道的空间描述符。平均池化反映每个位置上所有通道的平均响应强度，最大池化捕获最显著的单通道响应，两者从不同角度提取空间位置的显著性信息。将两个描述符拼接后，通过 $7 \times 7$ 卷积和Sigmoid激活生成空间注意力图：

$$M_s = \sigma(f^{7 \times 7}([\text{AvgPool}(X); \text{MaxPool}(X)]))$$

空间注意力图 $M_s \in \mathbb{R}^{H \times W \times 1}$ 与输入特征逐元素相乘，实现空间维度的差异化增强。

### 2.4.3 自注意力与交叉注意力机制

通道注意力和空间注意力均属于轻量级特征重标定机制，但未显式建模特征图中不同位置之间的关联关系。**自注意力机制**通过计算序列中每个位置与所有其他位置之间的相关性来建模全局依赖。

给定输入 $X \in \mathbb{R}^{N \times d}$，自注意力首先通过三个线性投影生成查询（Query）$Q$、键（Key）$K$ 和值（Value）$V$，然后通过缩放点积计算注意力权重并聚合信息：

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

其中，$QK^T$ 的第 $(i,j)$ 元素衡量位置 $i$ 与位置 $j$ 之间的语义相关性，$\sqrt{d_k}$ 为缩放因子以稳定Softmax的梯度。直观理解，$Q$ 表示每个位置"需要什么信息"，$K$ 表示每个位置"拥有什么信息"，注意力计算就是用查询去匹配键，从最相关位置的值中提取信息。实际应用中通常采用**多头注意力**，将特征划分为多个子空间独立计算注意力，以学习多种类型的关联模式：

$$\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)W_O$$

**交叉注意力机制**是自注意力的扩展，其查询与键/值来自不同的输入源。在自注意力中，$Q$、$K$、$V$ 均由同一输入生成；在交叉注意力中，查询来自输入 $X_1$，键和值来自另一输入 $X_2$：

$$Q = X_1 W_Q, \quad K = X_2 W_K, \quad V = X_2 W_V$$

交叉注意力以 $X_1$ 的特征为条件，从 $X_2$ 中选择性地提取最相关的信息。这种机制特别适合多模态融合——以一种模态的特征作为查询，从另一种模态中检索互补信息。与简单的特征拼接相比，交叉注意力能够根据语义相关性进行精细化的信息选取，避免无关信息的引入。本文在CrossModalMSK模块中采用交叉注意力实现光学与SAR特征的跨模态信息交互。

## 2.5 多模态遥感数据特性

本文的第二项工作涉及光学与SAR图像的融合分割，理解两种模态的数据特性是设计融合策略的基础。

**光学遥感图像**通过被动接收地表反射的可见光和近红外波段电磁波成像。不同地物对不同波长的选择性反射赋予了光学图像丰富的光谱信息，如健康植被在近红外波段反射率极高而在红色波段较低，水体在近红外波段几乎完全吸收。高分辨率光学图像还能提供清晰的纹理和边缘信息。然而，光学成像依赖日照且无法穿透云层，在恶劣天气下成像质量严重退化，且对光照变化和阴影敏感。

**SAR遥感图像**通过主动发射微波脉冲并接收回波成像，具备全天候、全天时的成像能力。微波能穿透云层和雨雾，在光学传感器无法工作的条件下仍可提供有效观测。SAR图像反映地表的后向散射特性，与地物的介电常数、表面粗糙度和几何结构相关，能提供光学图像无法获取的物理结构信息。然而，SAR图像受相干斑噪声干扰严重，且缺乏光谱信息，对地物类型的区分能力有限。

[此处插入图：同一区域的光学图像与SAR图像对比。左侧光学（色彩丰富、纹理清晰），右侧SAR（噪声明显但建筑结构突出），下方标注图。]

两种模态在信息维度上具有天然的互补性：光学图像擅长光谱属性和视觉纹理，SAR图像擅长几何结构且不受天气限制。融合两者可以全面表征地物特征，但两种模态在通道数（光学3-4通道 vs SAR单通道）、值域分布和噪声特性上的巨大差异，要求融合算法能够有效弥合模态鸿沟。

## 2.6 数据集与评价指标

### 2.6.1 实验数据集

本文在四个公开遥感数据集上进行实验验证，各数据集的基本信息如表2-1所示。

[此处插入表格：表2-1 实验数据集基本信息]

| 数据集 | 图像类型 | 图像尺寸 | GSD | 类别数 | 图像数量 | 训练/测试 |
|--------|---------|---------|-----|--------|---------|----------|
| ISPRS Potsdam | NIRRG航空影像 | 6000×6000 | 5cm | 6 | 38 | 23/14 |
| ISPRS Vaihingen | NIRRG航空影像 | ~2494×2064 | 9cm | 6 | 33 | 按常用划分 |
| LoveDA | RGB遥感影像 | 1024×1024 | 30cm | 7 | 5987 | 按官方划分 |
| WHU-OPT-SAR | 光学4通道+SAR单通道 | 5556×3704 | 5m | 7 | 100对 | 按常用划分 |

**ISPRS Potsdam数据集**覆盖德国波茨坦市城市区域，标注了不透水面、建筑物、低矮植被、树木、车辆和背景6个类别。该数据集以高分辨率（5cm GSD）和精细标注著称，主要挑战在于建筑物与不透水面的光谱特征高度相似，以及车辆目标尺度较小。本文排除标注存在错误的第710号图像，使用23幅训练、14幅测试，裁剪为512×512像素进行处理。

**ISPRS Vaihingen数据集**覆盖德国Vaihingen城市区域，类别与Potsdam相同。相比Potsdam，Vaihingen的GSD稍大、图像数量较少，建筑密度更高，阴影遮挡更显著，为模型在不同场景条件下的泛化能力评估提供了补充。

**LoveDA数据集**覆盖中国南京、常州和武汉三地的城市和乡村区域，标注了背景、建筑物、道路、水体、裸地、森林和农田7个类别。其显著特点是同时包含差异显著的城市和乡村场景，且类别不平衡严重，是评估模型综合分割能力的重要基准。

**WHU-OPT-SAR数据集**是目前最大的光学-SAR融合语义分割数据集，覆盖中国湖北省约50000平方公里区域。光学图像由GF-1卫星采集（RGBNIR四通道，原始分辨率2米），SAR图像由GF-3卫星采集（单通道，分辨率5米），两者通过重采样和几何配准实现逐像素对应。标注7个类别：背景、农田、城市、村庄、水体、森林和道路。该数据集的核心挑战在于光学与SAR在成像机理上的本质差异以及SAR相干斑噪声对融合过程的干扰。

[此处插入图：四个数据集的样例展示。每个数据集展示1-2组样例（原图+标注图），WHU-OPT-SAR展示光学图、SAR图和标注图三张。]

### 2.6.2 评价指标

本文采用以下指标评估模型性能，各指标均基于混淆矩阵 $\mathbf{M}$ 计算，其中 $M_{ij}$ 表示真实类别 $i$ 被预测为类别 $j$ 的像素数。

**总体精度（OA）** 衡量所有像素中被正确分类的比例：

$$OA = \frac{\sum_{i=0}^{K-1} M_{ii}}{\sum_{i=0}^{K-1}\sum_{j=0}^{K-1} M_{ij}}$$

OA直观但在类别不平衡时可能被多数类主导，需与其他指标结合使用。

**交并比（IoU）** 衡量某类别预测区域与真实区域的重叠度：

$$IoU_i = \frac{M_{ii}}{\sum_{j} M_{ij} + \sum_{j} M_{ji} - M_{ii}}$$

**平均交并比（mIoU）** 是所有类别IoU的均值，对每个类别赋予相同权重，不受类别不平衡影响，是语义分割最核心的综合评价指标：

$$mIoU = \frac{1}{K}\sum_{i=0}^{K-1} IoU_i$$

**F1分数** 是精确率和召回率的调和平均值。精确率 $P_i = \frac{M_{ii}}{\sum_j M_{ji}}$ 衡量"预测为类别 $i$ 的像素中真正属于该类别的比例"，召回率 $R_i = \frac{M_{ii}}{\sum_j M_{ij}}$ 衡量"真实属于类别 $i$ 的像素中被成功检出的比例"。F1分数综合考量两者：

$$F1_i = \frac{2 P_i R_i}{P_i + R_i}, \quad mF1 = \frac{1}{K}\sum_{i=0}^{K-1} F1_i$$

**计算效率指标** 包括参数量（Params，单位M）反映存储需求，浮点运算量（FLOPs，单位G）反映计算复杂度，推理速度（FPS，单位fps）反映实际部署效率。

## 2.7 本章小结

本章系统介绍了本文研究所涉及的核心理论与技术基础。首先，阐述了语义分割任务的概念和编码器-解码器架构如何协调语义理解与空间定位之间的矛盾，以及交叉熵损失与Dice损失联合使用的互补优势。其次，从连续SSM的数学定义出发，阐述了离散化过程中递推与卷积两种计算模式的等价性，分析了从S4固定参数到Mamba输入依赖选择性机制的关键技术突破，并介绍了SS2D通过四方向交叉扫描将SSM扩展至二维图像的策略。然后，介绍了SE和ECA通道注意力、空间注意力以及自注意力和交叉注意力的原理与特点，明确了各机制在本文不同模块中的应用位置。接着，分析了光学与SAR遥感数据各自的特性和互补关系。最后，介绍了ISPRS Potsdam、Vaihingen、LoveDA和WHU-OPT-SAR四个数据集的基本信息，以及mIoU、OA、mF1等评价指标的定义。本章内容为后续章节的方法设计与实验分析奠定了理论基础。
