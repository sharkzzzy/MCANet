class CrossModalFusionConv(nn.Module):
    """
    跨模态融合卷积
    """
    def __init__(self, in_channels, out_channels, factor=4.0):
        super(CrossModalFusionConv, self).__init__()
        dim = int(out_channels // factor)
        
        # 修复：in_channels应该是拼接后的通道数
        # in_channels = hidden_dim * 7 * 2 (SAR和OPT各7个hidden_dim)
        concat_channels = in_channels  # 这已经是正确的输入通道数
        
        # SAR分支处理
        self.sar_down = nn.Conv2d(concat_channels // 2, dim, kernel_size=1, stride=1)
        self.sar_conv_3x3 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1)
        self.sar_conv_5x5 = nn.Conv2d(dim, dim, kernel_size=5, stride=1, padding=2)
        self.sar_conv_7x7 = nn.Conv2d(dim, dim, kernel_size=7, stride=1, padding=3)
        
        # OPT分支处理
        self.opt_down = nn.Conv2d(concat_channels // 2, dim, kernel_size=1, stride=1)
        self.opt_conv_3x3 = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1)
        self.opt_conv_5x5 = nn.Conv2d(dim, dim, kernel_size=5, stride=1, padding=2)
        self.opt_conv_7x7 = nn.Conv2d(dim, dim, kernel_size=7, stride=1, padding=3)
        
        # 跨模态注意力
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=dim,
            num_heads=4,
            batch_first=True
        )
        
        # 空间注意力（保留原有的）
        self.spatial_attention = SpatialAttentionModule()
        
        # 融合和输出
        self.fusion = nn.Sequential(
            nn.Conv2d(dim * 2, dim, kernel_size=1),
            nn.BatchNorm2d(dim),
            nn.ReLU(inplace=True)
        )
        
        self.up = nn.Conv2d(dim, out_channels, kernel_size=1, stride=1)

    def forward(self, sar_x1, sar_x2, sar_x4, opt_x1, opt_x2, opt_x4):
        # SAR特征融合
        sar_fused = torch.cat([sar_x1, sar_x2, sar_x4], dim=1)
        sar_fused = self.sar_down(sar_fused)
        
        sar_3x3 = self.sar_conv_3x3(sar_fused)
        sar_5x5 = self.sar_conv_5x5(sar_fused)
        sar_7x7 = self.sar_conv_7x7(sar_fused)
        sar_multi = sar_3x3 + sar_5x5 + sar_7x7
        
        # OPT特征融合
        opt_fused = torch.cat([opt_x1, opt_x2, opt_x4], dim=1)
        opt_fused = self.opt_down(opt_fused)
        
        opt_3x3 = self.opt_conv_3x3(opt_fused)
        opt_5x5 = self.opt_conv_5x5(opt_fused)
        opt_7x7 = self.opt_conv_7x7(opt_fused)
        opt_multi = opt_3x3 + opt_5x5 + opt_7x7
        
        # 跨模态注意力
        B, C, H, W = sar_multi.shape
        sar_seq = sar_multi.permute(0, 2, 3, 1).reshape(B, H*W, C)
        opt_seq = opt_multi.permute(0, 2, 3, 1).reshape(B, H*W, C)
        
        # 双向交叉注意力
        cross_seq, _ = self.cross_attention(sar_seq, opt_seq, opt_seq)
        cross_feat = cross_seq.reshape(B, H, W, C).permute(0, 3, 1, 2)
        
        # 融合三个特征
        fused = self.fusion(torch.cat([sar_multi + cross_feat, opt_multi + cross_feat], dim=1))
        
        # 空间注意力
        fused = fused * self.spatial_attention(fused)
        
        # 输出
        x_out = self.up(fused)
        
        return x_out
