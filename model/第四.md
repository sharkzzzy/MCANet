随着遥感技术的飞速发展，尤其是卫星遥感和无人机遥感平台的日益普及，遥感图像的空间分辨率不断提高，所获取的图像数据量也在急剧增长[1]。遥感图像能够为地理环境研究提供广阔的观测视角，已被广泛应用于土地覆盖分类[2-3]、环境监测[4]、灾害评估[5]、城市规划[6]和精准农业[7]等领域，为国民经济建设和社会发展提供了重要的数据支撑。因此，如何从海量遥感图像中高效、准确地提取地物信息，已成为遥感领域亟待解决的关键问题。
语义分割是计算机视觉领域中的一项核心技术，旨在对图像中的每一个像素进行类别标注，在遥感图像分析中扮演着至关重要的角色[8]。该技术能够实现对建筑物、道路、植被、水体等不同地物类型的自动识别与精细划分，为上述应用场景提供高效的决策支持。近年来，基于深度学习的语义分割方法取得了显著进展，从早期的全卷积网络（Fully Convolutional Network, FCN）[9]到编码器-解码器架构的U-Net[10]，再到融合多尺度上下文信息的DeepLabV3+[11]，分割精度和效率均得到了大幅提升。
然而，高分辨率遥感图像的语义分割仍然面临诸多挑战。首先，遥感图像中地物类型多样、尺度差异显著，同一场景中既包含大面积的农田、水体等宏观地物，也存在车辆、小型建筑等细小目标，要求模型同时具备全局上下文建模能力和局部细节捕获能力。其次，遥感图像背景复杂，地物边界模糊，不同类别之间存在"同物异谱"和"异物同谱"现象，进一步加大了精确分割的难度。此外，高分辨率图像的数据量庞大，对算法的计算效率提出了更高的要求，如何在精度与效率之间取得平衡是一个重要的研究课题。
为应对上述挑战，研究者们不断探索更强大的模型架构。基于Transformer[12]的方法通过自注意力机制有效捕获了长距离依赖关系，在语义分割任务中展现出优越的性能。然而，自注意力机制的计算复杂度与输入序列长度呈二次方关系，当应用于高分辨率遥感图像时，巨大的计算开销严重制约了其实际部署。近年来，SSM [13]凭借其线性计算复杂度和全局序列建模能力，为解决这一矛盾提供了新的技术路径。以Mamba[14]为代表的选择性状态空间模型通过输入依赖的选择机制，在保持线性复杂度的同时实现了对长序列的高效建模，已在自然语言处理和计算机视觉等领域展现出巨大潜力。在遥感图像分割中，基于Mamba的方法[15]已初步验证了其在处理大规模场景时兼顾精度与效率的可行性。然而，现有方法仍存在全局上下文建模与局部细节增强在单一处理路径中相互耦合、注意力机制在网络不同阶段冗余堆叠等问题，限制了模型性能的进一步提升。
此外，在实际遥感应用中，单一模态的数据往往难以全面表征复杂地物的特征信息。光学图像虽然具有丰富的光谱和纹理信息，能够直观反映地表覆盖物的属性和类型，但易受云层遮挡、光照变化等环境因素的影响，在恶劣天气条件下成像质量显著下降。合成孔径雷达（Synthetic Aperture Radar, SAR）作为一种主动微波遥感技术，具备全天候、全天时的成像能力，能够穿透云层和部分地表覆盖物，提供稳定可靠的地表观测信息[16]。然而，SAR图像受相干斑噪声干扰严重，且缺乏光谱信息，对地物类型的区分能力有限。通过融合光学图像与SAR图像，可以充分发挥两种模态的互补优势，弥补单一数据源的不足，从而全面、准确地获取地表特征信息。然而，光学图像与SAR图像在成像机理、数据特性和信息表达形式上存在本质差异，如何有效弥合这种模态鸿沟、实现跨模态特征的充分融合，仍然是一个具有挑战性的研究问题。
综上所述，针对遥感图像语义分割中存在的全局与局部特征建模耦合、计算效率受限以及多模态特征融合困难等问题，开展基于状态空间模型的高效分割方法研究，并探索跨模态融合策略，对于推动遥感图像智能解译技术的发展具有重要的理论意义和应用价值。
